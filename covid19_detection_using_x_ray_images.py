# -*- coding: utf-8 -*-
"""Covid19_detection_using_X_ray_images.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dWAfGESHbXu2Fp2dCt3wi2Y2rODl8XN8

# TASK 1 : Import Libraries
"""



! pip install tensorflow
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D,Dropout,Flatten,Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt

"""# TASK 2 : Clone & Explore dataset"""





#clone the dataset from the github repository
! git clone https://github.com/education454/datasets.git

#set the path to the main dir
import os
main_dir="datasets/Data"
train_dir=os.path.join(main_dir,'train')
test_dir=os.path.join(main_dir,'test')
train_covid_dir=os.path.join(train_dir,'COVID19')
train_normal_dir=os.path.join(train_dir,'NORMAL')
test_covid_dir=os.path.join(test_dir,'COVID19')
test_normal_dir=os.path.join(test_dir,'NORMAL')
#set the path to the train dir

#set the path to the test dir


#directory with the training covid images

#directory with the training normal images

#directory with the testing covid images

#directory with the testing normal images

train_covid_names=os.listdir(train_covid_dir)
print(train_covid_names[:10])
train_normal_names=os.listdir(train_normal_dir)
print(train_normal_names[:10])
test_covid_names=os.listdir(test_covid_dir)
print(test_covid_names[:10])
test_normal_names=os.listdir(test_normal_dir)
print(test_normal_names[:10])

#print the total no of images present in each dir
print("total images present in traing set ",len(train_covid_names)+len(train_normal_names))
print("total images present in test set ",len(test_covid_names)+len(test_normal_names))

"""# TASK 3 : Data Visualization"""

# plot a grid of 16 images (8 images of Covid19 and 8 images of Normal)
import matplotlib.image as mping

#set the number of columns and rows
rows=4
cols=4

#set the figure size
fig=plt.gcf()
fig.set_size_inches(12,12)
covid_pic=[os.path.join(train_covid_dir,filename) for filename in train_covid_names[0:8]]
normal_pic=[os.path.join(train_normal_dir,filename) for filename in train_normal_names[0:8]]
#get the filenames from the covid & normal dir of the train dataset

#print the list
print(covid_pic)
print(normal_pic)
#merge the covid and normal list
merged_list=covid_pic+normal_pic

"""# TASK 4 : Data Preprocessing & Augmentation"""

# generate training,testing and validation batches
dgen_train=ImageDataGenerator(rescale=1./255,validation_split=0.2,zoom_range=0.2,horizontal_flip=True)
dgen_validation=ImageDataGenerator(rescale=1./255)
dgen_test=ImageDataGenerator(1./255)
train_generator=dgen_train.flow_from_directory(train_dir,target_size=(150,150),subset='training',batch_size=32,class_mode='binary')
validation_generator=dgen_train.flow_from_directory(train_dir,target_size=(150,150),subset='validation',batch_size=32,class_mode='binary')
test_generator=dgen_test.flow_from_directory(test_dir,target_size=(150,150),batch_size=32,class_mode='binary')

#get the class indices
train_generator.class_indices

#get the image shape
train_generator.image_shape

"""# TASK 5 : Build Convolutional Neural Network Model"""

model=Sequential();
# add the convolutional layer
# filters, size of filters,padding,activation_function,input_shape
model.add(Conv2D(32,(5,5),padding='SAME',activation='relu',input_shape=(150,150,3)))
# pooling layer
model.add(MaxPooling2D(pool_size=(2,2)))
# place a dropout layer
model.add(Dropout(0.5))
# add another convolutional kolayer

model.add(Conv2D(64,(5,5),padding='SAME',activation='relu'))

# pooling layer
model.add(MaxPooling2D(pool_size=(2,2)))
# place a dropout layer
model.add(Dropout(0.5))
# Flatten layer
model.add(Flatten())
# add a dense layer : amount of nodes, activation
model.add(Dense(256,activation='relu'))
# place a dropout layer
model.add(Dropout(0.5))
# 0.5 drop out rate is recommended, half input nodes will be dropped at each update

model.add(Dense(1,activation='sigmoid'))
model.summary()

"""# TASK 6 : Compile & Train the Model"""

#compile the model
model.compile(Adam(learning_rate=0.001),loss='binary_crossentropy',metrics=['accuracy'])

#train the model
history=model.fit(train_generator,epochs=3,validation_data=validation_generator)

"""# TASK 7 : Performance Evaluation"""

#get the keys of history object
history.history.keys()

#plot graph between training and validation loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['Training','Validation'])
plt.title('Traing and validation kolosses')
plt.xlabel('epoch')

#plot graph between training and validation accuarcy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.legend(['Training','Validation'])
plt.title('Traing and validation accuracy')
plt.xlabel('epoch')

# get the test acuarcy and loss
test_loss,test_acc=model.evaluate(test_generator)
print('test_loss: {} test_acc: {}'.format(test_loss,test_acc))

"""# TASK 8 : Prediction On New Data"""

import matplotlib.pyplot as plt
    import cv2
    from google.colab import files
    from keras.preprocessing import image
    from tensorflow.keras.utils import load_img,img_to_array
    uploaded=files.upload();
    for filename in uploaded.keys():
      img_path='/content/'+filename
      img=load_img(img_path,target_size=(150,150))

      images=img_to_array(img)
      img = cv2.cvtColor(images, cv2.COLOR_BGR2GRAY)
      plt.imshow(img)
      images=np.expand_dims(images,axis=0)
      prediction=model.predict(images)

      print(filename)

      if prediction==0:
        print('covid detected')
      else :
        print('your report is normal')